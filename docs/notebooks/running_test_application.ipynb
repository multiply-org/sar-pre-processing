{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of running sar-pre-processing package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Requirements\n",
    "\n",
    "- Installation of sar-pre-processing package\n",
    "    - Problem: gdal package might not be installed correctly\n",
    "- Installation of ESA's SNAP Toolbox (https://step.esa.int/main/download/snap-download/)\n",
    "    - SNAP Toolbox need libgfortran for specific operations but currently libgfortran is not installed during the installation process of SNAP therefore you might use\n",
    "```sudo apt-get install gfortran```\n",
    "- Sentinel-1 SLC data\n",
    "    - location where files are stored (locally)<br>\n",
    "    **or**\n",
    "    - use 2. to download data from the internet\n",
    "        - Free account for Copernicus Sentinel Data Hub needs to be created (https://scihub.copernicus.eu/dhus/#/self-registration)\n",
    "        - free disk space needed "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download sample data from Sentinel Data Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">Create Account (https://scihub.copernicus.eu/dhus/#/self-registration) and change user and password below</span>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to the API\n",
    "from sentinelsat import SentinelAPI, read_geojson, geojson_to_wkt\n",
    "from datetime import date\n",
    "user = 'username'\n",
    "password = 'password'\n",
    "# initialize settings\n",
    "api = SentinelAPI(user, password, 'https://scihub.copernicus.eu/apihub/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search by polygon (MNI test site coordinates), time, and SciHub query keywords\n",
    "footprint = geojson_to_wkt(read_geojson('coordinates_mni.geojson'))\n",
    "products = api.query(footprint,\n",
    "                     date=('20200101', '20200120'),\n",
    "                     platformname='Sentinel-1',\n",
    "                     producttype='SLC')\n",
    "print('Following products will be downloaded')\n",
    "print(api.to_dataframe(products).title.values)\n",
    "\n",
    "print('These {} product need {} Gb of disk space'.format(len(products), api.get_products_size(products)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Start download process (<span style=\"color:red\">Attention: might take a while and data will requries some free disk space</span>)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download all results from the search\n",
    "# files will be downloaded to specified path\n",
    "import os\n",
    "path = \"/path/to/data/\"\n",
    "try:\n",
    "    os.makedirs(path)\n",
    "except: FileExistsError\n",
    "api.download_all(products, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Use sar-pre-processing package to process Sentinel-1 SLC data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set paths for\n",
    "- input_folder (location with stored Sentinel-1 SLC data)\n",
    "- output_folder (location where processed data will be stored)\n",
    "- gpt_loction (gpt is located in the bin folder of your SNAP installation)' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = path\n",
    "output_folder = path\n",
    "gpt_location = os.path.expanduser('~/snap/bin/gpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create config file with information about input, output and gpt loction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "with open('sample_config_file.yaml') as stream:\n",
    "   data = yaml.safe_load(stream)\n",
    "\n",
    "data['input_folder'] = input_folder\n",
    "data['output_folder'] = output_folder\n",
    "data['gpt'] = gpt_location\n",
    "\n",
    "with open('test_config_file.yaml', 'wb') as stream:\n",
    "   yaml.safe_dump(data, stream, default_flow_style=False, \n",
    "                  explicit_start=True, allow_unicode=True, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start pre-processing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sar_pre_processing.sar_pre_processor import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "processing = SARPreProcessor(config='test_config_file.yaml')\n",
    "processing.create_processing_file_list()\n",
    "print('start step 1')\n",
    "processing.pre_process_step1()\n",
    "print('start step 2')\n",
    "processing.pre_process_step2()\n",
    "print('start step 3')\n",
    "processing.pre_process_step3()\n",
    "print('start solve projection problem')\n",
    "processing.solve_projection_problem()\n",
    "print('start add netcdf information')\n",
    "processing.add_netcdf_information()\n",
    "print('start create netcdf stack')\n",
    "processing.create_netcdf_stack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. View processed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load netcdf file with processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "print(output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import netCDF4\n",
    "    print(\"netCDF4 installed - requirement satisfied.\")\n",
    "except ModuleNotFoundError:\n",
    "    print('netCDF4 module not installed!')\n",
    "    yes = input(\"Do you want do install now? (type y)\")\n",
    "    if yes in ['yes', 'y', 'Y']:\n",
    "        print(\"trying to install..\")\n",
    "        ! pip install netCDF4 --user\n",
    "    else:\n",
    "        print(\"not installing..\")\n",
    "\n",
    "from netCDF4 import Dataset\n",
    "import numpy as np\n",
    "\n",
    "my_example_nc_file = output_folder + 'Data.nc'\n",
    "data = Dataset(my_example_nc_file, mode='r') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View information about dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data from netcdf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.variables['orbitdirection'][:]\n",
    "data.variables['time'][:]\n",
    "lons = data.variables['lon'][:]\n",
    "lats = data.variables['lat'][:]\n",
    "vv = data.variables['sigma0_vv_multi'][:]\n",
    "\n",
    "vv_units = data.variables['sigma0_vv_multi'].units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Close netcdf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot vv polorized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import matplotlib\n",
    "    print(\"netCDF4 installed - requirement satisfied.\")\n",
    "except ModuleNotFoundError:\n",
    "    print('matplotlib module not installed!')\n",
    "    yes = input(\"Do you want do install now? (type y)\")\n",
    "    if yes in ['yes', 'y', 'Y']:\n",
    "        print(\"trying to install..\")\n",
    "        ! pip install matplotlib --user\n",
    "    else:\n",
    "        print(\"not installing..\")\n",
    "        \n",
    "%matplotlib inline\n",
    "from ipywidgets import interactive\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def f(x):\n",
    "    # Problem: border pixel might be zero or negative\n",
    "    # pixel eqal or smaller than zero are set to nan\n",
    "    array = np.copy(vv[x])\n",
    "    array[array <= 0] = np.nan\n",
    "    # plot backscatter data in dB scale\n",
    "    plt.imshow(10*np.log10(array))\n",
    "    cbar = plt.colorbar()\n",
    "    cbar.set_label('dB')\n",
    "    plt.clim(-25, 0)\n",
    "\n",
    "interactive_plot = interactive(f, x=(0,len(vv)-1))\n",
    "interactive_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
