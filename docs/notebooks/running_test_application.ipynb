{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of running sar-pre-processing package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Requirements\n",
    "\n",
    "- Installation of sar-pre-processing package\n",
    "- Installation of ESA's SNAP Toolbox (https://step.esa.int/main/download/snap-download/)\n",
    "    - Currently only SNAP version 8.0 can be downloaded from the website. To update SNAP to a version >8.0.3 please start the SNAP software. You will be asked if you want to search for update. After the updates are installed you need to restart SNAP to initialize the installed updates.\n",
    "    - SNAP Toolbox (Linux version) need libgfortran for specific operations but currently libgfortran is not installed during the installation process of SNAP therefore you might use\n",
    "```sudo apt-get install gfortran```\n",
    "- Sentinel-1 SLC data\n",
    "    - location where files are stored (locally)<br>\n",
    "    **or**\n",
    "    - use 2. to download data from the internet\n",
    "        - Free account for Copernicus Sentinel Data Hub needs to be created (https://scihub.copernicus.eu/dhus/#/self-registration)\n",
    "        - free disk space needed\n",
    "- For plotting purposes within this jupyter notebook matplotlib needs to be installed\n",
    "    - ```conda install -c conda-forge matplotlib```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download sample data from Sentinel Data Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">Create Account (https://scihub.copernicus.eu/dhus/#/self-registration) and change user and password below</span>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to the API\n",
    "from sentinelsat import SentinelAPI, read_geojson, geojson_to_wkt\n",
    "from datetime import date\n",
    "user = 'username'\n",
    "password = 'password'\n",
    "# initialize settings\n",
    "api = SentinelAPI(user, password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search by polygon (MNI test site coordinates), time, and SciHub query keywords\n",
    "footprint = geojson_to_wkt(read_geojson('coordinates_mni.geojson'))\n",
    "products = api.query(footprint,\n",
    "                     date=('20210601', '20210615'),\n",
    "                     platformname='Sentinel-1',\n",
    "                     producttype='SLC')\n",
    "print('Following products will be downloaded')\n",
    "print(api.to_dataframe(products).title.values)\n",
    "\n",
    "print('These {} product need {} Gb of disk space'.format(len(products), api.get_products_size(products)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Start download process (<span style=\"color:red\">Attention: might take a while and data will requries some free disk space</span>)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download all results from the search\n",
    "# files will be downloaded to specified path\n",
    "import os\n",
    "path = \"/path/to/data/\"\n",
    "try:\n",
    "    os.makedirs(path)\n",
    "except: FileExistsError\n",
    "api.download_all(products, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Use sar-pre-processing package to process Sentinel-1 SLC data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set paths for\n",
    "- input_folder (path to stored Sentinel-1 SLC data (zip files) e.g. \"~/Downloads\")\n",
    "- output_folder (path where processed data will be stored e.g. \"~/output\")\n",
    "- gpt_loction (gpt is located in the bin folder of your SNAP installation)' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = os.path.expanduser(path)\n",
    "output_folder = os.path.expanduser(path)\n",
    "gpt_location = os.path.expanduser('~/snap/bin/gpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create config file with information about input, output and gpt loction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "with open('sample_config_file.yaml') as stream:\n",
    "   data = yaml.safe_load(stream)\n",
    "\n",
    "data['input_folder'] = input_folder\n",
    "data['output_folder'] = output_folder\n",
    "data['gpt'] = gpt_location\n",
    "\n",
    "with open('test_config_file.yaml', 'wb') as stream:\n",
    "   yaml.safe_dump(data, stream, default_flow_style=False, \n",
    "                  explicit_start=True, allow_unicode=True, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional config options which might be useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_config_file.yaml') as stream:\n",
    "   data = yaml.safe_load(stream)\n",
    "\n",
    "# Filter option\n",
    "## Filter via year of interes\n",
    "#data['year'] = '2021'\n",
    "\n",
    "## Define region of interest\n",
    "#data['region']['lr']['lat'] = 48.2 # lower right latitude\n",
    "#data['region']['lr']['lon'] = 11.9 # lower right longitude\n",
    "#data['region']['ul']['lat'] = 48.4 # upper left latitude\n",
    "#data['region']['ul']['lon'] = 11.6 # upper left longitude\n",
    "#data['region']['subset'] = 'yes'\n",
    "\n",
    "## Define multi-temporal filtering properties\n",
    "#data['speckle_filter']['multi_temporal']['apply'] = 'yes'\n",
    "#data['speckle_filter']['multi_temporal']['files'] = '5' # Number of files used for multi temporal filtering\n",
    "\n",
    "## Define incidence angle for normalization\n",
    "#data['normalization_angle'] = '35'\n",
    "\n",
    "## Processing of one single file instead of a time series\n",
    "#data['speckle_filter']['multi_temporal']['apply'] = 'no'\n",
    "\n",
    "with open('test_config_file.yaml', 'wb') as stream:\n",
    "   yaml.safe_dump(data, stream, default_flow_style=False, \n",
    "                  explicit_start=True, allow_unicode=True, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start pre-processing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sar_pre_processing.sar_pre_processor import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "processing = SARPreProcessor(config='test_config_file.yaml')\n",
    "processing.create_processing_file_list()\n",
    "print('start step 1')\n",
    "processing.pre_process_step1()\n",
    "print('start step 2')\n",
    "processing.pre_process_step2()\n",
    "print('start step 3')\n",
    "processing.pre_process_step3()\n",
    "print('start add netcdf information')\n",
    "processing.add_netcdf_information()\n",
    "print('start create netcdf stack')\n",
    "processing.create_netcdf_stack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. View processed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load netcdf file with processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "print(output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "import numpy as np\n",
    "\n",
    "my_example_nc_file = os.path.join(output_folder, 'data.nc')\n",
    "data = Dataset(my_example_nc_file, mode='r') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View information about dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data from netcdf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.variables['orbitdirection'][:]\n",
    "data.variables['time'][:]\n",
    "lons = data.variables['lon'][:]\n",
    "lats = data.variables['lat'][:]\n",
    "vv = data.variables['sigma0_vv_single'][:]\n",
    "\n",
    "vv_units = data.variables['sigma0_vv_single'].units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Close netcdf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot vv polorized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from ipywidgets import interactive\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def f(x):\n",
    "    # Problem: border pixel might be zero or negative\n",
    "    # pixel eqal or smaller than zero are set to nan\n",
    "    array = np.copy(vv[x])\n",
    "    array[array <= 0] = np.nan\n",
    "    # plot backscatter data in dB scale\n",
    "    plt.imshow(10*np.log10(array))\n",
    "    cbar = plt.colorbar()\n",
    "    cbar.set_label('dB')\n",
    "    plt.clim(-25, 0)\n",
    "\n",
    "interactive_plot = interactive(f, x=(0,len(vv)-1))\n",
    "interactive_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
